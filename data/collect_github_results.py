#!/usr/bin/env python3
"""
GitHub Issuesë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ì‚¬ìš©ì ì—°êµ¬ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”:
1. GitHub Issues APIë¥¼ ì‚¬ìš©í•´ ì‚¬ìš©ì ì—°êµ¬ ê²°ê³¼ë¥¼ ìˆ˜ì§‘
2. JSON ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ê³  ì •ë¦¬
3. ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ë¶„ì„
4. ê²°ê³¼ë¥¼ CSVì™€ JSONìœ¼ë¡œ ì €ì¥
5. ê¸°ë³¸ í†µê³„ ë° ì‹œê°í™” ì œê³µ
"""

import json
import os
import csv
import requests
from datetime import datetime
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from typing import Dict, List, Any

class GitHubResultsCollector:
    def __init__(self, token: str, owner: str = "deep-overflow", repo: str = "InterGenEval_user_study"):
        """
        GitHub Issues ê²°ê³¼ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        
        Args:
            token: GitHub Personal Access Token
            owner: Repository ì†Œìœ ì
            repo: Repository ì´ë¦„
        """
        self.token = token
        self.owner = owner
        self.repo = repo
        self.headers = {
            'Authorization': f'token {token}',
            'Accept': 'application/vnd.github.v3+json'
        }
        self.base_url = f"https://api.github.com/repos/{owner}/{repo}"
        
    def collect_study_results(self) -> List[Dict[str, Any]]:
        """
        GitHub Issuesì—ì„œ ì‚¬ìš©ì ì—°êµ¬ ê²°ê³¼ë¥¼ ìˆ˜ì§‘
        
        Returns:
            List of parsed study results
        """
        print("ğŸ” Collecting user study results from GitHub Issues...")
        
        # Get issues with user-study-result label
        url = f"{self.base_url}/issues"
        params = {
            'labels': 'user-study-result',
            'state': 'all',
            'per_page': 100
        }
        
        all_results = []
        page = 1
        
        while True:
            params['page'] = page
            response = requests.get(url, headers=self.headers, params=params)
            
            if response.status_code != 200:
                print(f"âŒ Error fetching issues: {response.status_code}")
                break
                
            issues = response.json()
            if not issues:
                break
                
            print(f"ğŸ“„ Processing page {page} ({len(issues)} issues)...")
            
            for issue in issues:
                try:
                    result = self.parse_issue_result(issue)
                    if result:
                        all_results.append(result)
                except Exception as e:
                    print(f"âš ï¸ Error parsing issue #{issue['number']}: {e}")
                    
            page += 1
            
        print(f"âœ… Collected {len(all_results)} valid study results")
        return all_results
    
    def parse_issue_result(self, issue: Dict[str, Any]) -> Dict[str, Any]:
        """
        GitHub Issueì—ì„œ ì‚¬ìš©ì ì—°êµ¬ ê²°ê³¼ íŒŒì‹±
        
        Args:
            issue: GitHub issue data
            
        Returns:
            Parsed study result data
        """
        body = issue['body']
        
        # Extract JSON data from markdown code block
        json_start = body.find('```json')
        json_end = body.find('```', json_start + 7)
        
        if json_start == -1 or json_end == -1:
            raise ValueError("No JSON data found in issue body")
            
        json_str = body[json_start + 7:json_end].strip()
        
        try:
            result_data = json.loads(json_str)
            
            # Add GitHub metadata
            result_data['github_issue_number'] = issue['number']
            result_data['github_created_at'] = issue['created_at']
            result_data['github_url'] = issue['html_url']
            
            return result_data
            
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON data: {e}")
    
    def analyze_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ìˆ˜ì§‘ëœ ê²°ê³¼ ë°ì´í„° ë¶„ì„
        
        Args:
            results: List of study results
            
        Returns:
            Analysis summary
        """
        print("ğŸ“Š Analyzing collected results...")
        
        analysis = {
            'total_participants': len(results),
            'total_comparisons': 0,
            'model_comparisons': defaultdict(lambda: {'wins': 0, 'total': 0}),
            'comparison_sets': defaultdict(list),
            'demographics': defaultdict(list),
            'study_durations': [],
            'completion_times': []
        }
        
        for result in results:
            # Study duration
            duration_minutes = result.get('studyDuration', 0) / 1000 / 60
            analysis['study_durations'].append(duration_minutes)
            
            # Completion time
            analysis['completion_times'].append(result.get('timestamp'))
            
            # Demographics
            demographics = result.get('demographics', {})
            for key, value in demographics.items():
                analysis['demographics'][key].append(value)
            
            # Process responses
            responses = result.get('responses', {})
            for comparison_set, videos in responses.items():
                analysis['total_comparisons'] += len(videos)
                
                for video_id, choice_data in videos.items():
                    # Handle both string and object formats for choice data
                    if isinstance(choice_data, str):
                        choice = choice_data
                    elif isinstance(choice_data, dict):
                        choice = choice_data.get('choice')
                    else:
                        continue
                        
                    if choice in ['A', 'B']:
                        # Extract model names from comparison set
                        models = comparison_set.split('_vs_')
                        if len(models) == 2:
                            chosen_model = models[0] if choice == 'A' else models[1]
                            other_model = models[1] if choice == 'A' else models[0]
                            
                            # Record win for chosen model
                            analysis['model_comparisons'][chosen_model]['wins'] += 1
                            analysis['model_comparisons'][chosen_model]['total'] += 1
                            analysis['model_comparisons'][other_model]['total'] += 1
                            
                            # Store comparison data
                            analysis['comparison_sets'][comparison_set].append({
                                'participant': result.get('participantId'),
                                'video_id': video_id,
                                'choice': choice,
                                'chosen_model': chosen_model,
                                'timestamp': choice_data.get('timestamp') if isinstance(choice_data, dict) else None
                            })
        
        # Calculate win rates
        for model, stats in analysis['model_comparisons'].items():
            stats['win_rate'] = stats['wins'] / stats['total'] if stats['total'] > 0 else 0
            
        return analysis
    
    def save_results(self, results: List[Dict[str, Any]], analysis: Dict[str, Any], output_dir: str = "github_analysis_output"):
        """
        ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
        
        Args:
            results: Raw study results
            analysis: Analysis summary
            output_dir: Output directory
        """
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Save raw results
        raw_file = os.path.join(output_dir, f"raw_results_{timestamp}.json")
        with open(raw_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ Raw results saved to: {raw_file}")
        
        # Save analysis summary
        analysis_file = os.path.join(output_dir, f"analysis_summary_{timestamp}.json")
        with open(analysis_file, 'w', encoding='utf-8') as f:
            # Convert defaultdict to regular dict for JSON serialization
            analysis_json = json.loads(json.dumps(analysis, default=str))
            json.dump(analysis_json, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“Š Analysis summary saved to: {analysis_file}")
        
        # Save model comparison CSV
        csv_file = os.path.join(output_dir, f"model_comparison_{timestamp}.csv")
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['Model', 'Wins', 'Total_Comparisons', 'Win_Rate'])
            
            for model, stats in analysis['model_comparisons'].items():
                writer.writerow([model, stats['wins'], stats['total'], f"{stats['win_rate']:.3f}"])
        print(f"ğŸ“ˆ Model comparison saved to: {csv_file}")
        
        # Create visualizations
        self.create_visualizations(analysis, output_dir, timestamp)
        
    def create_visualizations(self, analysis: Dict[str, Any], output_dir: str, timestamp: str):
        """
        ê²°ê³¼ ì‹œê°í™” ìƒì„±
        
        Args:
            analysis: Analysis data
            output_dir: Output directory
            timestamp: Timestamp for file naming
        """
        plt.style.use('seaborn-v0_8')
        
        # Model win rate comparison
        models = list(analysis['model_comparisons'].keys())
        win_rates = [analysis['model_comparisons'][model]['win_rate'] for model in models]
        total_comps = [analysis['model_comparisons'][model]['total'] for model in models]
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Win rate bar chart
        bars = ax1.bar(models, win_rates, color='skyblue', alpha=0.8)
        ax1.set_title('Model Win Rates', fontsize=14, fontweight='bold')
        ax1.set_ylabel('Win Rate')
        ax1.set_ylim(0, 1)
        ax1.tick_params(axis='x', rotation=45)
        
        # Add value labels on bars
        for bar, rate in zip(bars, win_rates):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{rate:.3f}', ha='center', va='bottom')
        
        # Total comparisons bar chart
        bars2 = ax2.bar(models, total_comps, color='lightcoral', alpha=0.8)
        ax2.set_title('Total Comparisons per Model', fontsize=14, fontweight='bold')
        ax2.set_ylabel('Number of Comparisons')
        ax2.tick_params(axis='x', rotation=45)
        
        # Add value labels on bars
        for bar, count in zip(bars2, total_comps):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{count}', ha='center', va='bottom')
        
        plt.tight_layout()
        plot_file = os.path.join(output_dir, f"model_comparison_{timestamp}.png")
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š Visualization saved to: {plot_file}")
        
        # Study duration histogram
        if analysis['study_durations']:
            plt.figure(figsize=(10, 6))
            plt.hist(analysis['study_durations'], bins=15, color='lightgreen', alpha=0.7, edgecolor='black')
            plt.title('Study Duration Distribution', fontsize=14, fontweight='bold')
            plt.xlabel('Duration (minutes)')
            plt.ylabel('Number of Participants')
            plt.grid(True, alpha=0.3)
            
            # Add statistics
            mean_duration = sum(analysis['study_durations']) / len(analysis['study_durations'])
            plt.axvline(mean_duration, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_duration:.1f} min')
            plt.legend()
            
            duration_plot = os.path.join(output_dir, f"study_duration_{timestamp}.png")
            plt.savefig(duration_plot, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"â±ï¸ Duration plot saved to: {duration_plot}")

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("ğŸš€ GitHub Issues User Study Results Collector")
    print("=" * 50)
    
    # GitHub token - ì‹¤ì œ ì‚¬ìš© ì‹œ í™˜ê²½ë³€ìˆ˜ë‚˜ ì„¤ì •íŒŒì¼ì—ì„œ ì½ì–´ì˜¤ê¸°
    token = input("ğŸ”‘ GitHub Personal Access Tokenì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    
    if not token:
        print("âŒ GitHub tokenì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    try:
        # Initialize collector
        collector = GitHubResultsCollector(token)
        
        # Collect results
        results = collector.collect_study_results()
        
        if not results:
            print("âŒ ìˆ˜ì§‘ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # Analyze results
        analysis = collector.analyze_results(results)
        
        # Print summary
        print("\nğŸ“Š ë¶„ì„ ìš”ì•½:")
        print(f"   ì´ ì°¸ê°€ì ìˆ˜: {analysis['total_participants']}")
        print(f"   ì´ ë¹„êµ íšŸìˆ˜: {analysis['total_comparisons']}")
        print(f"   í‰ê·  ì—°êµ¬ ì‹œê°„: {sum(analysis['study_durations'])/len(analysis['study_durations']):.1f}ë¶„")
        
        print("\nğŸ† ëª¨ë¸ë³„ ìŠ¹ë¥ :")
        for model, stats in sorted(analysis['model_comparisons'].items(), 
                                 key=lambda x: x[1]['win_rate'], reverse=True):
            print(f"   {model}: {stats['win_rate']:.3f} ({stats['wins']}/{stats['total']})")
        
        # Save results
        collector.save_results(results, analysis)
        
        print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()